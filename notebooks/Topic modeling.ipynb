{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import yaml\n",
    "from pyyoutube import Api\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import f1_score, silhouette_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(YOUTUBE_API_KEY, videoId, maxResults, nextPageToken):\n",
    "    \"\"\"\n",
    "    Получение информации со страницы с видео\n",
    "    \"\"\"\n",
    "    YOUTUBE_URI = 'https://www.googleapis.com/youtube/v3/commentThreads?key={KEY}&textFormat=plainText&' + \\\n",
    "        'part=snippet&videoId={videoId}&maxResults={maxResults}&pageToken={nextPageToken}'\n",
    "    format_youtube_uri = YOUTUBE_URI.format(KEY=YOUTUBE_API_KEY,\n",
    "                                            videoId=videoId,\n",
    "                                            maxResults=maxResults,\n",
    "                                            nextPageToken=nextPageToken)\n",
    "    content = requests.get(format_youtube_uri).text\n",
    "    data = json.loads(content)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_text_of_comment(data):\n",
    "    \"\"\"\n",
    "    Получение комментариев из полученных данных под одним видео\n",
    "    \"\"\"\n",
    "    comms = set()\n",
    "    for item in data['items']:\n",
    "        comm = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "        comms.add(comm)\n",
    "    return comms\n",
    "\n",
    "\n",
    "def get_all_comments(YOUTUBE_API_KEY, query, count_video=10, limit=30, maxResults=10, nextPageToken=''):\n",
    "    \"\"\"\n",
    "    Выгрузка maxResults комментариев\n",
    "    \"\"\"\n",
    "    api = Api(api_key=YOUTUBE_API_KEY)\n",
    "    video_by_keywords = api.search_by_keywords(q=query,\n",
    "                                               search_type=[\"video\"],\n",
    "                                               count=count_video,\n",
    "                                               limit=limit)\n",
    "    videoId = [x.id.videoId for x in video_by_keywords.items]\n",
    "\n",
    "    comments_all = []\n",
    "    for id_video in videoId:\n",
    "        try:\n",
    "            data = get_data(YOUTUBE_API_KEY,\n",
    "                            id_video,\n",
    "                            maxResults=maxResults,\n",
    "                            nextPageToken=nextPageToken)\n",
    "            comment = list(get_text_of_comment(data))\n",
    "            comments_all.append(comment)\n",
    "        except:\n",
    "            continue\n",
    "    comments = sum(comments_all, [])\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join('/Users/miracl6/airflow-mlflow-tutorial/config/params_all.yaml')\n",
    "config = yaml.safe_load(open(config_path))['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = config['SEED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SEED': 10,\n",
       " 'clustering': {'affinity': 'cosine',\n",
       "  'count_max_clusters': 15,\n",
       "  'silhouette_metric': 'euclidean'},\n",
       " 'comments': {'YOUTUBE_API_KEY': 'AIzaSyCPYNxHdsk6_-UX60p9Hm65cPXWXifut9A',\n",
       "  'count_video': 5,\n",
       "  'limit': 30,\n",
       "  'maxResults': 20,\n",
       "  'nextPageToken': '',\n",
       "  'query': 'дата сайенс'},\n",
       " 'cross_val': {'test_size': 0.3},\n",
       " 'dir_folder': '/Users/miracl6/airflow-mlflow-tutorial',\n",
       " 'model': {'class_weight': 'balanced'},\n",
       " 'model_lr': 'LogisticRegression',\n",
       " 'model_vec': 'vector_tfidf',\n",
       " 'name_experiment': 'my_second',\n",
       " 'stopwords': 'russian',\n",
       " 'tf_model': {'max_features': 300}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = get_all_comments(**config['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Кто ждёт новый год \\nЯ - лайк \\nНет - коммент',\n",
       " 'Наша команда уже второй год занимается обработкой и разметкой данных, растем в этом направлении. Заинтересованных лиц просьба писать в личку.',\n",
       " 'ля, я такой в начале, что еще за сатанист',\n",
       " 'Как правильно? Газпром нефтИ или нЕфти?',\n",
       " 'Раскатал про ИИ по красоте!) Простому смертному стало более понятно, что такое машин лернинг',\n",
       " 'Я студент финансового университета, учусь по направлению Анализ больших данных и принятие экономических решений. Как мне попасть на стажировку в Газпром?',\n",
       " 'Качественно сделано и довольно интересно. Подпишусь на ваш канал)',\n",
       " 'А как же вопросы \"где учиться\" и \"сколько можно зарабатывать\"?)))',\n",
       " 'Я закончил бакалавриат по специальности разработка и эксплуатация нгм. Сейчас обучаюсь в магистратуре по направлению \"Big data\". Подскажите, есть ли возможность попасть на работу по данной специальности на шельфовое месторождение?',\n",
       " 'Очень хорошо и понятно все обьяснил! Спасибо']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    \"\"\"\n",
    "    Удаление эмоджи из текста\n",
    "    \"\"\"\n",
    "    emoji_pattern = re.compile(\"[\"u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u'\\U00010000-\\U0010ffff'\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\u3030\"\n",
    "                               u\"\\ufe0f\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "\n",
    "def remove_links(string):\n",
    "    \"\"\"\n",
    "    Удаление ссылок\n",
    "    \"\"\"\n",
    "    string = re.sub(r'http\\S+', '', string)  # remove http links\n",
    "    string = re.sub(r'bit.ly/\\S+', '', string)  # rempve bitly links\n",
    "    string = re.sub(r'www\\S+', '', string)  # rempve bitly links\n",
    "    string = string.strip('[link]')  # remove [links]\n",
    "    return string\n",
    "\n",
    "\n",
    "def preprocessing(string, stopwords, stem):\n",
    "    \"\"\"\n",
    "    Простой препроцессинг текста, очистка, лематизация, удаление коротких слов\n",
    "    \"\"\"\n",
    "    string = remove_emoji(string)\n",
    "    string = remove_links(string)\n",
    "\n",
    "    # удаление символов \"\\r\\n\"\n",
    "    str_pattern = re.compile(\"\\r\\n\")\n",
    "    string = str_pattern.sub(r'', string)\n",
    "\n",
    "    # очистка текста от символов\n",
    "    string = re.sub('(((?![а-яА-Я ]).)+)', ' ', string)\n",
    "    # лематизация\n",
    "    string = ' '.join([\n",
    "        re.sub('\\\\n', '', ' '.join(stem.lemmatize(s))).strip()\n",
    "        for s in string.split()\n",
    "    ])\n",
    "    # удаляем слова короче 3 символов\n",
    "    string = ' '.join([s for s in string.split() if len(s) > 3])\n",
    "    # удаляем стоп-слова\n",
    "    string = ' '.join([s for s in string.split() if s not in stopwords])\n",
    "    return string\n",
    "\n",
    "\n",
    "def get_clean_text(data, stopwords):\n",
    "    \"\"\"\n",
    "    Получение текста в преобразованной после очистки\n",
    "    матричном виде, а также модель векторизации\n",
    "    \"\"\"\n",
    "    # Простой препроцессинг текста\n",
    "    stem = Mystem()\n",
    "    comments = [preprocessing(x, stopwords, stem) for x in data]\n",
    "    # Удаление комментов, которые имеют меньше, чем 5 слов\n",
    "    comments = [y for y in comments if len(y.split()) > 5]\n",
    "    #common_texts = [i.split(' ') for i in comments]\n",
    "    return comments\n",
    "\n",
    "\n",
    "def vectorize_text(data, tfidf):\n",
    "    \"\"\"\n",
    "    Получение матрицы кол-ва слов в комменариях\n",
    "    Очистка от пустых строк\n",
    "    \"\"\"\n",
    "    # Векторизация\n",
    "    X_matrix = tfidf.transform(data).toarray()\n",
    "    # Удаляем строки в матрице с пустыми значениями\n",
    "    mask = (np.nan_to_num(X_matrix) != 0).any(axis=1)\n",
    "    return X_matrix[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_clean = get_clean_text(comments, stopwords.words(config['stopwords']))\n",
    "tfidf = TfidfVectorizer(**config['tf_model']).fit(comments_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SEED': 10,\n",
       " 'clustering': {'affinity': 'cosine',\n",
       "  'count_max_clusters': 15,\n",
       "  'silhouette_metric': 'euclidean'},\n",
       " 'comments': {'YOUTUBE_API_KEY': 'AIzaSyCPYNxHdsk6_-UX60p9Hm65cPXWXifut9A',\n",
       "  'count_video': 5,\n",
       "  'limit': 30,\n",
       "  'maxResults': 20,\n",
       "  'nextPageToken': '',\n",
       "  'query': 'дата сайенс'},\n",
       " 'cross_val': {'test_size': 0.3},\n",
       " 'dir_folder': '/Users/miracl6/airflow-mlflow-tutorial',\n",
       " 'model': {'class_weight': 'balanced'},\n",
       " 'model_lr': 'LogisticRegression',\n",
       " 'model_vec': 'vector_tfidf',\n",
       " 'name_experiment': 'my_first',\n",
       " 'stopwords': 'russian',\n",
       " 'tf_model': {'max_features': 300}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['команда второй заниматься обработка разметка данный расти направление заинтересованный лицо просьба писать личка',\n",
       " 'раскатать красота простой смертный становиться понятно машина лернинг',\n",
       " 'студент финансовый университет учиться направление анализ большой данный принятие экономический решение попадать стажировка газпром',\n",
       " 'качественно сделать довольно интересно подписываться канал',\n",
       " 'заканчивать бакалавриат специальность разработка эксплуатация обучаться магистратура направление подсказывать возможность попадать работа данна специальность шельфовый месторождение',\n",
       " 'дата сайентист нефтянка говорить квартира получаться взять ипотека начинать понимать страна приходить туда',\n",
       " 'газпром нефть дата сатанист взаимосвязь иметь ввиду название канал',\n",
       " 'хотеть купить брать ипотека вариант грустно',\n",
       " 'вопрос специалист нужный большой данные большой данные сколько возможно выгружать память человек диск нейронный сеть правда дата сайентист самый сексуальный профессия ученый нефтяник ученый нефтянка применяться дата сайенс нефтянка скрываться большой брат робот захватить смотреть сериал черный зеркало блиц попадать работа газпром нефть посоветовать хотеть становиться дата сайентист хотеть работать газпром нефть заходить карьерный портал регистрироваться откликаться вакансия',\n",
       " 'мочь делать закладывать бояться закладывать запросто значит бояться']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_clean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_matrix = vectorize_text(comments_clean, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['авторитарный',\n",
       " 'алгоритм',\n",
       " 'анализ',\n",
       " 'аналитика',\n",
       " 'аналитический',\n",
       " 'артефакт',\n",
       " 'багамы',\n",
       " 'базовый',\n",
       " 'бакалавриат',\n",
       " 'бали']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(data, count_max_clusters, random_state, affinity,\n",
    "                 silhouette_metric):\n",
    "    \"\"\"\n",
    "    Подбор наилучшего числа кластеров, возвращает полученные кластера тематик\n",
    "    \"\"\"\n",
    "    cluster_labels = {}\n",
    "    silhouette_mean = []\n",
    "\n",
    "    for i in range(2, count_max_clusters, 1):\n",
    "        clf = SpectralClustering(n_clusters=i,\n",
    "                                 affinity=affinity,\n",
    "                                 random_state=random_state)\n",
    "        #clf = KMeans(n_clusters=n, max_iter=1000, n_init=1)\n",
    "        clf.fit(data)\n",
    "        labels = clf.labels_\n",
    "        cluster_labels[i] = labels\n",
    "        silhouette_mean.append(\n",
    "            silhouette_score(data, labels, metric=silhouette_metric))\n",
    "    n_clusters = silhouette_mean.index(max(silhouette_mean)) + 2\n",
    "    return cluster_labels[n_clusters]\n",
    "\n",
    "\n",
    "def get_f1_score(y_test, y_pred, unique_cluster_labels):\n",
    "    \"\"\"\n",
    "    Возращает результат обучения классификатора по тематикам\n",
    "    \"\"\"\n",
    "    return f1_score(\n",
    "        y_test, y_pred,\n",
    "        average='macro') \\\n",
    "        if len(unique_cluster_labels) > 2 \\\n",
    "        else f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miracl6/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/Users/miracl6/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/Users/miracl6/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/Users/miracl6/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/Users/miracl6/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/Users/miracl6/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/Users/miracl6/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/Users/miracl6/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/Users/miracl6/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/Users/miracl6/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/Users/miracl6/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/Users/miracl6/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/Users/miracl6/opt/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    }
   ],
   "source": [
    "cluster_labels = get_clusters(X_matrix,\n",
    "                                 random_state=SEED,\n",
    "                                 **config['clustering'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SEED': 10,\n",
       " 'clustering': {'affinity': 'cosine',\n",
       "  'count_max_clusters': 15,\n",
       "  'silhouette_metric': 'euclidean'},\n",
       " 'comments': {'YOUTUBE_API_KEY': 'AIzaSyCPYNxHdsk6_-UX60p9Hm65cPXWXifut9A',\n",
       "  'count_video': 5,\n",
       "  'limit': 30,\n",
       "  'maxResults': 20,\n",
       "  'nextPageToken': '',\n",
       "  'query': 'дата сайенс'},\n",
       " 'cross_val': {'test_size': 0.3},\n",
       " 'dir_folder': '/Users/miracl6/airflow-mlflow-tutorial',\n",
       " 'model': {'class_weight': 'balanced'},\n",
       " 'model_lr': 'LogisticRegression',\n",
       " 'model_vec': 'vector_tfidf',\n",
       " 'name_experiment': 'my_first',\n",
       " 'stopwords': 'russian',\n",
       " 'tf_model': {'max_features': 300}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 0, 3, 6, 0, 6, 0, 5], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_matrix,\n",
    "                                                    cluster_labels,\n",
    "                                                    **config['cross_val'],\n",
    "                                                    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression(**config['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export MLFLOW_REGISTRY_URI=../mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'vector_tfidf' already exists. Creating a new version of this model...\n",
      "2021/05/02 19:53:43 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: vector_tfidf, version 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12980699 0.13219332 0.141417   0.12500189 0.12521816 0.11938949\n",
      "  0.11138085 0.1155923 ]\n",
      " [0.13225054 0.09461199 0.14431436 0.14921074 0.12746151 0.12149697\n",
      "  0.11319859 0.1174553 ]\n",
      " [0.1488154  0.09091486 0.15653628 0.14699363 0.12095594 0.11566808\n",
      "  0.10800232 0.11211349]\n",
      " [0.14166712 0.09029179 0.1767976  0.12378369 0.12853311 0.11464353\n",
      "  0.11344233 0.11084083]\n",
      " [0.14735099 0.09412684 0.14295515 0.12872404 0.12654938 0.12060076\n",
      "  0.12294893 0.11674391]\n",
      " [0.14852655 0.08947448 0.13987674 0.12342287 0.12322714 0.11324573\n",
      "  0.15235379 0.10987269]\n",
      " [0.1433901  0.09291234 0.14875431 0.12435637 0.12450994 0.14043332\n",
      "  0.11060968 0.11503393]\n",
      " [0.17761867 0.09219381 0.13923505 0.12629707 0.12340639 0.11763627\n",
      "  0.10961023 0.11400252]\n",
      " [0.13568458 0.0949781  0.15717993 0.13047939 0.12802549 0.12203414\n",
      "  0.11358408 0.11803429]\n",
      " [0.13182455 0.09333186 0.15002128 0.12495374 0.13229934 0.13286687\n",
      "  0.1191945  0.11550786]\n",
      " [0.14957397 0.09164231 0.15114628 0.12472615 0.12895741 0.12000372\n",
      "  0.1208868  0.11306337]\n",
      " [0.1392777  0.09596093 0.14717823 0.12958826 0.12980173 0.12360369\n",
      "  0.11503374 0.1195557 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '29' of model 'vector_tfidf'.\n",
      "Registered model 'LogisticRegression' already exists. Creating a new version of this model...\n",
      "2021/05/02 19:53:43 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: LogisticRegression, version 29\n",
      "Created version '29' of model 'LogisticRegression'.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(config['name_experiment'])\n",
    "with mlflow.start_run():\n",
    "    clf_lr.fit(X_train, y_train)\n",
    "    print(clf_lr.predict_proba(X_test))\n",
    "\n",
    "    # Логирование модели и параметров\n",
    "    mlflow.log_param(\n",
    "        'f1', get_f1_score(y_test, clf_lr.predict(X_test),\n",
    "                           set(cluster_labels)))\n",
    "    mlflow.sklearn.log_model(\n",
    "        tfidf,\n",
    "        artifact_path=\"vector\",\n",
    "        registered_model_name=f\"{config['model_vec']}\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        clf_lr,\n",
    "        artifact_path='model_lr',\n",
    "        registered_model_name=f\"{config['model_lr']}\")\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlflow/2/da17c6f5dbce43aeaa6727a3674d2376/artifacts'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_artifact_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_version_model(config_name, client):\n",
    "    \"\"\"\n",
    "    Получение последней версии модели из MLFlow\n",
    "    \"\"\"\n",
    "    dict_push = {}\n",
    "    for count, value in enumerate(\n",
    "        client.search_model_versions(f\"name='{config_name}'\")):\n",
    "        # client.list_registered_models()):\n",
    "        # Все версии модели\n",
    "        dict_push[count] = value\n",
    "    return dict(list(dict_push.items())[-1][1])['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "last_version_lr = get_version_model(config['model_lr'], client)\n",
    "last_version_vec = get_version_model(config['model_vec'], client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_version_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_version_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
